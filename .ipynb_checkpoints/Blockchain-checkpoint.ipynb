{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLockchain DB Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! whoami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plyvel configparser ecdsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import mmap\n",
    "import struct\n",
    "import pickle\n",
    "import stat\n",
    "import plyvel\n",
    "from configparser import ConfigParser\n",
    "from blockchain_index import DBBlockIndex\n",
    "\n",
    "from btc_utils import BTCUtils as Utils\n",
    "from btcpy.btcpy.structs import block as btcpy_block\n",
    "from btcpy.btcpy.setup import setup\n",
    "\n",
    "from db_structs.db_blockchain import DBBlockchain, DBBlock, DBTx, DBTxo, DBTxi, DBDirectory\n",
    "\n",
    "import sys\n",
    "import importlib  \n",
    "# sys.path.append('../python-bitcoin-blockchain-parser')\n",
    "# from blockchain_parser import block #, blockchain\n",
    "\n",
    "\n",
    "setup('mainnet')\n",
    "BITCOIN_CONSTANT = b\"\\xf9\\xbe\\xb4\\xd9\"\n",
    "\n",
    "\n",
    "class BlockchainDB:\n",
    "    _CURRENT_BLOCK_IDX = ''\n",
    "    _CURRENT_BLOCK = ''\n",
    "    _BLOCK_INDEXES = ''\n",
    "    _CONFIG_FILE = 'app.conf'\n",
    "    _CONFIG = []\n",
    "    blockIndexes = ''    \n",
    "    BLKCHN_FILE=''\n",
    "    path_index = ''\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.load_config();\n",
    "        \n",
    "        self.PATH_BTC_ROOT = self._CONFIG_BLOCKCHAIN['path_btc_root']\n",
    "        self._PATH_BLKS_FOLDER = self._CONFIG_BLOCKCHAIN['path_btc_blocks']\n",
    "        self._PATH_INDEX_FOLDER = self._CONFIG_BLOCKCHAIN['path_btc_index']\n",
    "        self._PATH_CHAINSTATE_FOLER = self._CONFIG_BLOCKCHAIN['path_btc_chainstate']\n",
    "        self._PATH_TXINDEX_FOLDER = self._CONFIG_BLOCKCHAIN['path_btc_txindex']  \n",
    "        pass;\n",
    "    \n",
    "    # Constant separating blocks in the .blk files\n",
    "    \n",
    "    def load_config(self):\n",
    "        self._CONFIG_MDB = Utils.load_config(self._CONFIG_FILE, 'mdb')\n",
    "        self._CONFIG_BLOCKCHAIN = Utils.load_config(self._CONFIG_FILE, 'blockchain')\n",
    "        self._CONFIG_RAY = Utils.load_config(self._CONFIG_FILE, 'ray')\n",
    "\n",
    "    def get_files(self, path):\n",
    "        \"\"\"\n",
    "        Given the path to the .bitcoin directory, returns the sorted list of .blk\n",
    "        files contained in that directory\n",
    "        \"\"\"\n",
    "        if not stat.S_ISDIR(os.stat(path)[stat.ST_MODE]):\n",
    "            return [path]\n",
    "        files = os.listdir(path)\n",
    "        files = [f for f in files if f.startswith(\"blk\") and f.endswith(\".dat\")]\n",
    "        files = map(lambda x: os.path.join(path, x), files)\n",
    "        return sorted(files)\n",
    "\n",
    "\n",
    "    def get_blocks(self, blockfile):\n",
    "        \"\"\"\n",
    "        Given the name of a .blk file, for every block contained in the file,\n",
    "        yields its raw hexadecimal value\n",
    "        \"\"\"\n",
    "        with open(blockfile, \"rb\") as f:\n",
    "            if os.name == 'nt':\n",
    "                size = os.path.getsize(f.name)\n",
    "                raw_data = mmap.mmap(f.fileno(), size, access=mmap.ACCESS_READ)\n",
    "            else:\n",
    "                # Unix-only call, will not work on Windows, see python doc.\n",
    "                raw_data = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)\n",
    "            length = len(raw_data)\n",
    "            offset = 0\n",
    "            block_count = 0\n",
    "            while offset < (length - 4):\n",
    "                if raw_data[offset:offset+4] == BITCOIN_CONSTANT:\n",
    "                    offset += 4\n",
    "                    size = struct.unpack(\"<I\", raw_data[offset:offset+4])[0]\n",
    "                    offset += 4 + size\n",
    "                    block_count += 1\n",
    "                    yield raw_data[offset-size:offset]\n",
    "                else:\n",
    "                    offset += 1\n",
    "            raw_data.close()\n",
    "\n",
    "\n",
    "    def get_block(self, blockfile, offset):\n",
    "        \"\"\"Extracts a single block from the blockfile at the given offset\"\"\"\n",
    "        with open(blockfile, \"rb\") as f:\n",
    "            f.seek(offset - 4)  # Size is present 4 bytes before the db offset\n",
    "            size, = struct.unpack(\"<I\", f.read(4))\n",
    "            return f.read(size)\n",
    "    \n",
    "    def load_blkchn_file(self, blkchn_index=1):\n",
    "        self.BLKCHN_FILE = '{0}/blk{1}.dat'.format(self._PATH_BLKS_FOLDER,'{:05d}'.format(blkchn_index));\n",
    "        \n",
    "    def getBlockIndexes(self, index):\n",
    "        \"\"\"There is no method of leveldb to close the db (and release the lock).\n",
    "        This creates problem during concurrent operations.\n",
    "        This function also provides caching of indexes.\n",
    "        \"\"\"\n",
    "        if self.path_index != index:\n",
    "            db = plyvel.DB(index, compression=None, create_if_missing=True)\n",
    "            self.blockIndexes = [DBBlockIndex(Utils.format_hash(k[1:]), v)\n",
    "                                 for k, v in db.iterator() if k[0] == ord('b')]\n",
    "            db.close()\n",
    "            self.blockIndexes.sort(key=lambda x: x.height)\n",
    "            self.path_index = index\n",
    "        return self.blockIndexes\n",
    "    \n",
    "    def get_ordered_blocks(self, index, start=0, end=None, cache=None):\n",
    "        \"\"\"Yields the blocks contained in the .blk files as per\n",
    "        the heigt extract from the leveldb index present at path\n",
    "        index maintained by bitcoind.\n",
    "        \"\"\"\n",
    "\n",
    "        blockIndexes = None\n",
    "\n",
    "        if cache and os.path.exists(cache):\n",
    "            # load the block index cache from a previous index\n",
    "            with open(cache, 'rb') as f:\n",
    "                blockIndexes = pickle.load(f)\n",
    "            print(\"Loading existing cache file {0} \\n\".format(cache))\n",
    "\n",
    "        if blockIndexes is None:\n",
    "            # build the block index\n",
    "            blockIndexes = self.getBlockIndexes(index)\n",
    "            if cache and not os.path.exists(cache):\n",
    "                # cache the block index for re-use next time\n",
    "                print(\"Creating new cache file {0} \\n\".format(cache))\n",
    "                with open(cache, 'wb') as f:\n",
    "                    pickle.dump(blockIndexes, f)\n",
    "\n",
    "        # remove small forks that may have occured while the node was live.\n",
    "        # Occassionally a node will receive two different solutions to a block\n",
    "        # at the same time. The Leveldb index saves both, not pruning the\n",
    "        # block that leads to a shorter chain once the fork is settled without\n",
    "        # \"-reindex\"ing the bitcoind block data. This leads to at least two\n",
    "        # blocks with the same height in the database.\n",
    "        # We throw out blocks that don't have at least 6 other blocks on top of\n",
    "        # it (6 confirmations).\n",
    "        orphans = []  # hold blocks that are orphans with < 6 blocks on top\n",
    "        last_height = -1\n",
    "        for i, blockIdx in enumerate(blockIndexes):\n",
    "            if last_height > -1:\n",
    "                # if this block is the same height as the last block an orphan\n",
    "                # occurred, now we have to figure out which of the two to keep\n",
    "                if blockIdx.height == last_height:\n",
    "\n",
    "                    # loop through future blocks until we find a chain 6 blocks\n",
    "                    # long that includes this block. If we can't find one\n",
    "                    # remove this block as it is invalid\n",
    "                    if self._index_confirmed(blockIndexes[i:]):\n",
    "\n",
    "                        # if this block is confirmed, the unconfirmed block is\n",
    "                        # the previous one. Remove it.\n",
    "                        orphans.append(blockIndexes[i - 1].hash)\n",
    "                    else:\n",
    "\n",
    "                        # if this block isn't confirmed, remove it.\n",
    "                        orphans.append(blockIndexes[i].hash)\n",
    "\n",
    "            last_height = blockIdx.height\n",
    "\n",
    "        # filter out the orphan blocks, so we are left only with block indexes\n",
    "        # that have been confirmed\n",
    "        # (or are new enough that they haven't yet been confirmed)\n",
    "        blockIndexes = list(filter(lambda block: block.hash not in orphans, blockIndexes))\n",
    "\n",
    "        if end is None:\n",
    "            end = len(blockIndexes)\n",
    "\n",
    "        if end < start:\n",
    "            blockIndexes = list(reversed(blockIndexes))\n",
    "            start = len(blockIndexes) - start\n",
    "            end = len(blockIndexes) - end\n",
    "        \n",
    "        _PREV_BLK_FILE = -1\n",
    "        for blkIdx in blockIndexes[start:end]:\n",
    "            self._CURRENT_BLOCK_IDX = blkIdx;\n",
    "            if blkIdx.file == -1 or blkIdx.data_pos == -1:\n",
    "                break\n",
    "            #print(\"BlkIndex: \", json.dumps(blkIdx.to_json(), indent=2))\n",
    "            blkFile = os.path.join(self._PATH_BLKS_FOLDER, \"blk%05d.dat\" % blkIdx.file)\n",
    "\n",
    "            # block struct from python_bitcoin_blockchain_parser\n",
    "            #yield block.Block(self.get_block(blkFile, blkIdx.data_pos), blkIdx.height)\n",
    "            #######################################\n",
    "            if self._CURRENT_BLOCK_IDX.file > _PREV_BLK_FILE :\n",
    "                db_blkchn = DBBlockchain();\n",
    "                db_blkchn.from_btcpy_obj(self._CURRENT_BLOCK_IDX);\n",
    "                _PREV_BLK_FILE = self._CURRENT_BLOCK_IDX.file;\n",
    "                del db_blkchn;\n",
    "            ######################################\n",
    "            \n",
    "            #block_struct from btcpy block\n",
    "            yield btcpy_block.Block.deserialize(self.get_block(blkFile, blkIdx.data_pos))\n",
    "            \n",
    "            \n",
    "            \n",
    "    def parse(self):\n",
    "        #blkchn = blockchain.Blockchain(os.path.expanduser(self._BLK_FOLDER_PATH))\n",
    "        for blk in self.get_ordered_blocks(os.path.expanduser(self._PATH_INDEX_FOLDER), end = 100):\n",
    "            print(blk.header)\n",
    "    \n",
    "    @staticmethod       \n",
    "    def remove_blkchain_lock():\n",
    "        LOCK_FILE =\"/root/.bitcoin/blocks/index/LOCK\"\n",
    "\n",
    "        ## If file exists, delete it ##\n",
    "        if os.path.isfile(LOCK_FILE):\n",
    "            os.remove(LOCK_FILE)\n",
    "        else:    ## Show an error ##\n",
    "            print(\"Error: %s file not found\" % LOCK_FILE)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BlockchainDB.remove_blkchain_lock()\n",
    "#!sudo rm -rf /root/.bitcoin/blocks/index/LOCK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from db_structs.db_blockchain import global_connect, global_disconnect, DBBlockchain, DBBlock, DBTx, DBTxo, DBTxi, DBUtxo, DBDirectory\n",
    "\n",
    "global_connect()\n",
    "\n",
    "blkchain = BlockchainDB();\n",
    "for blk in blkchain.get_ordered_blocks(os.path.expanduser(blkchain._PATH_INDEX_FOLDER), start=298851, end=666000):\n",
    "    blkchain._CURRENT_BLOCK = blk;\n",
    "    #print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    #print(json.dumps(blk.header.to_json(), indent=2))\n",
    "    ###################################\n",
    "    db_blk=DBBlock()\n",
    "    db_blk.from_btcpy_obj(blkchain._CURRENT_BLOCK_IDX)\n",
    "    del db_blk\n",
    "    #################################\n",
    "    \n",
    "   \n",
    "    #print(\"##########################################################################################\")\n",
    "    for txn_obj in blk.txns:\n",
    "        #print(json.dumps(txn_obj.to_json(), indent=2))\n",
    "        ################################################\n",
    "        db_utxo = DBUtxo();\n",
    "        db_utxo.from_btcpy_obj(blkchain._CURRENT_BLOCK_IDX, txn_obj)\n",
    "        del db_utxo\n",
    "        ###############################################\n",
    "        \n",
    "           \n",
    "global_disconnect()    \n",
    "print(\"All blocks processed\")\n",
    "#! ./remove_btc_index_lock.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workdir/Tutorials/Crypto/Bitcoin/apps/blockchain_db'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cache file\n",
    "\n",
    "import json\n",
    "from db_structs.db_blockchain import global_connect, global_disconnect, DBBlockchain, DBBlock, DBTx, DBTxo, DBTxi, DBUtxo, DBDirectory\n",
    "\n",
    "global_connect()\n",
    "\n",
    "blkchain = BlockchainDB();\n",
    "for blk in blkchain.get_ordered_blocks(os.path.expanduser(blkchain._PATH_INDEX_FOLDER), start=0, end=600000, cache='/workdir/Tutorials/Crypto/Bitcoin/apps/blockchain_db/cache/idx_cache'):\n",
    "    blkchain._CURRENT_BLOCK = blk;\n",
    "    #print(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\n",
    "    #print(json.dumps(blk.header.to_json(), indent=2))\n",
    "    ###################################\n",
    "    db_blk=DBBlock()\n",
    "    db_blk.from_btcpy_obj(blkchain._CURRENT_BLOCK_IDX)\n",
    "    del db_blk\n",
    "    #################################\n",
    "    \n",
    "   \n",
    "    #print(\"##########################################################################################\")\n",
    "    #for txn_obj in blk.txns:\n",
    "        #print(json.dumps(txn_obj.to_json(), indent=2))\n",
    "        ################################################\n",
    "        #db_utxo = DBUtxo();\n",
    "        #db_utxo.from_btcpy_obj(blkchain._CURRENT_BLOCK_IDX, txn_obj)\n",
    "        #del db_utxo\n",
    "        ###############################################\n",
    "        \n",
    "           \n",
    "global_disconnect()    \n",
    "print(\"All blocks processed\")\n",
    "#! ./remove_btc_index_lock.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_block(blk_obj, blkchain_idx, q_del):\n",
    "    db_blk=DBBlock();\n",
    "    db_blk.form_btcpy_obj(blkchain_idx);\n",
    "    for txn_obj in blk_obj.txns:\n",
    "        db_utxo = DBUtxo();\n",
    "        db_utxo.from_btcpy_obj(blkchain_idx, txn_obj);\n",
    "    del db_blk;\n",
    "    del db_utxo;\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'btc_utils.py'\n",
    "\n",
    "from binascii import hexlify\n",
    "import hashlib, codecs\n",
    "from configparser import ConfigParser\n",
    "from bson.binary import Binary as BsonBinary\n",
    "\n",
    "class BTCUtils(object):\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_config(config_file, section_name):\n",
    "        config = ConfigParser()\n",
    "        config.read(config_file)\n",
    "        return config[section_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def b2x(b):\n",
    "        return b.hex();\n",
    "    \n",
    "    @staticmethod\n",
    "    def s2x(s):\n",
    "        return hexlify(bytes(s, 'utf-8'))\n",
    "    \n",
    "    @staticmethod\n",
    "    def x2b(x):\n",
    "        return codecs.decode(x, 'hex')\n",
    "    \n",
    "    @staticmethod\n",
    "    def x2bson(x):\n",
    "        return BsonBinary(BTCUtils.x2b(x), 5)\n",
    "    \n",
    "    @staticmethod\n",
    "    def s2bson(s):\n",
    "        return BTCUtils.x2bson(BTCUtils.s2x(s))\n",
    "    \n",
    "    @staticmethod\n",
    "    def i2x(i,nBits):\n",
    "        return hex(i)[2:].zfill(nBits);\n",
    "    \n",
    "    @staticmethod\n",
    "    def seed2pvk(s_str, nHash=1):\n",
    "        seed_b = s.encode('utf8') #converts string to bytes\n",
    "        for x in range(nHash):\n",
    "            sha_pvk = hashlib.sha256(seed_b)\n",
    "            seed_b = sha_pvk;\n",
    "        pvk_b = sha_pvk.digest()\n",
    "        return pvk_b\n",
    "    \n",
    "    @staticmethod\n",
    "    def btc_ripemd160(data):\n",
    "        h1 = hashlib.sha256(data).digest()\n",
    "        r160 = hashlib.new(\"ripemd160\")\n",
    "        r160.update(h1)\n",
    "        return r160.digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def double_sha256(data):\n",
    "        return hashlib.sha256(hashlib.sha256(data).digest()).digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def format_hash(hash_):\n",
    "        return str(hexlify(hash_[::-1]).decode(\"utf-8\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_uint32(data):\n",
    "        assert(len(data) == 4)\n",
    "        return struct.unpack(\"<I\", data)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_uint64(data):\n",
    "        assert(len(data) == 8)\n",
    "        return struct.unpack(\"<Q\", data)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_varint(data):\n",
    "        assert(len(data) > 0)\n",
    "        size = int(data[0])\n",
    "        assert(size <= 255)\n",
    "\n",
    "        if size < 253:\n",
    "            return size, 1\n",
    "\n",
    "        if size == 253:\n",
    "            format_ = '<H'\n",
    "        elif size == 254:\n",
    "            format_ = '<I'\n",
    "        elif size == 255:\n",
    "            format_ = '<Q'\n",
    "        else:\n",
    "            # Should never be reached\n",
    "            assert 0, \"unknown format_ for size : %s\" % size\n",
    "\n",
    "        size = struct.calcsize(format_)\n",
    "        return struct.unpack(format_, data[1:size+1])[0], size + 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_json(json_obj, indent=2):\n",
    "        json_formatted_str = json.dumps(json.load(json_obj), indent=indent)\n",
    "        return json_formatted_str\n",
    "    \n",
    "    @staticmethod\n",
    "    def val_non_satoshi(val_satoshi):\n",
    "        return val_satoshi/100000000\n",
    "    \n",
    "    @staticmethod\n",
    "    def val_satoshi(val_non_satoshi):\n",
    "        return val_non_satoshi * 100000000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'blockchain_index.py'\n",
    "\n",
    "\n",
    "from struct import unpack\n",
    "\n",
    "from utils import Utils\n",
    "\n",
    "BLOCK_HAVE_DATA = 8\n",
    "BLOCK_HAVE_UNDO = 16\n",
    "\n",
    "\n",
    "def _read_varint(raw_hex):\n",
    "    \"\"\"\n",
    "    Reads the weird format of VarInt present in src/serialize.h of bitcoin core\n",
    "    and being used for storing data in the leveldb.\n",
    "    This is not the VARINT format described for general bitcoin serialization\n",
    "    use.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    pos = 0\n",
    "    while True:\n",
    "        data = raw_hex[pos]\n",
    "        pos += 1\n",
    "        n = (n << 7) | (data & 0x7f)\n",
    "        if data & 0x80 == 0:\n",
    "            return n, pos\n",
    "        n += 1\n",
    "\n",
    "\n",
    "class DBBlockIndex(object):\n",
    "    def __init__(self, blk_hash, raw_hex):\n",
    "        self.hash = blk_hash\n",
    "        pos = 0\n",
    "        n_version, i = _read_varint(raw_hex[pos:])\n",
    "        pos += i\n",
    "        self.height, i = _read_varint(raw_hex[pos:])\n",
    "        pos += i\n",
    "        self.status, i = _read_varint(raw_hex[pos:])\n",
    "        pos += i\n",
    "        self.n_tx, i = _read_varint(raw_hex[pos:])\n",
    "        pos += i\n",
    "        if self.status & (BLOCK_HAVE_DATA | BLOCK_HAVE_UNDO):\n",
    "            self.file, i = _read_varint(raw_hex[pos:])\n",
    "            pos += i\n",
    "        else:\n",
    "            self.file = -1\n",
    "\n",
    "        if self.status & BLOCK_HAVE_DATA:\n",
    "            self.data_pos, i = _read_varint(raw_hex[pos:])\n",
    "            pos += i\n",
    "        else:\n",
    "            self.data_pos = -1\n",
    "        if self.status & BLOCK_HAVE_UNDO:\n",
    "            self.undo_pos, i = _read_varint(raw_hex[pos:])\n",
    "            pos += i\n",
    "\n",
    "        assert(pos + 80 == len(raw_hex))\n",
    "        self.version, p, m, time, bits, self.nonce = unpack(\n",
    "            \"<I32s32sIII\",\n",
    "            raw_hex[-80:]\n",
    "        )\n",
    "        self.prev_hash = Utils.format_hash(p)\n",
    "        self.merkle_root = Utils.format_hash(m)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DBBlockIndex(%s, height=%d, file_no=%d, file_pos=%d)\" \\\n",
    "               % (self.hash, self.height, self.file, self.data_pos)\n",
    "    \n",
    "    def to_json(self):\n",
    "        return {\n",
    "            'blk_hash': self.hash,\n",
    "            'prev_hash': self.prev_hash,\n",
    "            'height': self.height,\n",
    "            'file': self.file,\n",
    "            'nTxns': self.n_tx,\n",
    "            'status': self.status,\n",
    "            'data_posn': self.data_pos,\n",
    "            'merkle_root' : self.merkle_root,\n",
    "            'version': self.version,\n",
    "            'nounce':self.nonce\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'db_mongo.conf'\n",
    "\n",
    "[mdb]\n",
    "    #host = 127.0.0.1\n",
    "    #host = 192.168.0.229 \n",
    "    #db_btc = btc_miner\n",
    "    \n",
    "    host = 192.168.0.111    \n",
    "    db_btc = btc_nas    \n",
    "    \n",
    "    port = 27017\n",
    "    username = root\n",
    "    passwd = chinnus_pwd\n",
    "    #cln_keybank = btc_keybank\n",
    "    cln_keybank = btc_keybank_temp\n",
    "    cln_blocks = btc_blocks\n",
    "    \n",
    "[blockchain]\n",
    "    cln_blockchains = btc_blkchains,\n",
    "    cln_blocks = btc_blks,\n",
    "    cln_txns = btc_txs,\n",
    "    cln_txi = btc_txi,\n",
    "    cln_txo = btc_txo,\n",
    "    cln_directory = btc_directory,\n",
    "    cln_keybank = btc_keybank\n",
    "\n",
    "[ray]\n",
    "    mode = worker\n",
    "    num_cpus = 12\n",
    "    redis_address = 192.168.0.229\n",
    "    redis_port = 6379\n",
    "    redis_passwd = letsdoit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'db_mongo.py'\n",
    "\n",
    "import pymongo\n",
    "from configparser import ConfigParser\n",
    "from utils import Utils\n",
    "\n",
    "class DbMongo(object):\n",
    "    usrName, usrPwd, dbURI, dbPort = 'root', 'pwd', 127.0.0.1 , 27017;\n",
    "    config = null;\n",
    "    \n",
    "    \n",
    "    mdb_config = Utils.load_config('db_mongo.conf', 'mdb')\n",
    "    ray_config = Utils.load_config('db_mongo.conf', 'ray')\n",
    "    blkchain_config = Utils.load_config('db_mongo.conf', 'blockchain')\n",
    "    mdb_client = DbMongo.db_connect(mdb_config['username'], mdb_config['passwd'], mdb_config['host'], mdb_config['port'])\n",
    "    mdb_db = DbMongo.db_select(mdb_client, mdb_config['db_btc'])\n",
    "    mdb_cln_keybank = DbMongo.db_select_cln(mdb_db, blkchain_config['cln_keybank'])\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.config =configparser.ConfigParser();\n",
    "        \n",
    "    @staticmethod\n",
    "    def db_connect(usrName, usrPwd, dbURI, dbPort):\n",
    "        return pymongo.MongoClient(\"mongodb:///{0}:{1}@{2}:{3}\".format(usrName, usrPwd, dbURI, dbPort))\n",
    "    \n",
    "    @staticmethod\n",
    "    def db_select(dbClient, dbName):\n",
    "        return dbClient[dbName]\n",
    "    \n",
    "    @staticmethod\n",
    "    def db_select_cln(dbName, collectionName):\n",
    "        return dbName[collectionName]\n",
    "    \n",
    "    @staticmethod\n",
    "    def db_upload_keypairs(keysCln, pbk_b, pvk_b):\n",
    "        keysCln.insert_one({'pbk': BsonBinary(pbk_b, 5), 'pvk': BsonBinary(pvk_b, 5)})\n",
    "        \n",
    "    @staticmethod    \n",
    "    def db_upload_ripemd160(keysCln, PbK, PvK, RipeMD160):\n",
    "        keysCln.insert_one({'pbk': BsonBinary(PbK,5), 'pvk': BsonBinary(PvK,5), 'ripemd160': BsonBinary(RipeMD160,5) })\n",
    "        \n",
    "    @staticmethod    \n",
    "    def db_upload_public_address(keysCln, PbK, PvK, RipeMD160, PbA):\n",
    "        keysCln.insert_one({'pbk': BsonBinary(PbK,5), 'pvk': BsonBinary(PvK,5), 'ripemd160': BsonBinary(RipeMD160,5), 'pba_b58': BsonBinary(PbA, 5) })\n",
    "        \n",
    "    @staticmethod   \n",
    "    def db_bulk_upload(keysCln, bulkKeypairs):\n",
    "        keysCln.insert_many(bulkKeypairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile 'btc_utils.py'\n",
    "\n",
    "from binascii import hexlify\n",
    "import hashlib, codecs, struct\n",
    "from configparser import ConfigParser\n",
    "from bson.binary import Binary as BsonBinary\n",
    "\n",
    "class BTCUtils(object):    \n",
    "    @staticmethod\n",
    "    def load_config(config_file, section_name):\n",
    "        config = ConfigParser()\n",
    "        config.read(config_file)\n",
    "        return config[section_name]\n",
    "    \n",
    "    @staticmethod\n",
    "    def b2x(b):\n",
    "        return b.hex();\n",
    "    \n",
    "    @staticmethod\n",
    "    def x2b(x):\n",
    "        return codecs.decode(x, 'hex')\n",
    "    \n",
    "    @staticmethod\n",
    "    def x2bson(x):\n",
    "        return BsonBinary(BTCUtils.x2b(x),5) \n",
    "    \n",
    "    @staticmethod\n",
    "    def i2x(i,nBits):\n",
    "        return hex(i)[2:].zfill(nBits);\n",
    "    \n",
    "    @staticmethod\n",
    "    def seed2pvk(s_str, nHash=1):\n",
    "        seed_b = s.encode('utf8') #converts string to bytes\n",
    "        for x in range(nHash):\n",
    "            sha_pvk = hashlib.sha256(seed_b)\n",
    "            seed_b = sha_pvk;\n",
    "        pvk_b = sha_pvk.digest()\n",
    "        return pvk_b\n",
    "    \n",
    "    @staticmethod\n",
    "    def btc_ripemd160(data):\n",
    "        h1 = hashlib.sha256(data).digest()\n",
    "        r160 = hashlib.new(\"ripemd160\")\n",
    "        r160.update(h1)\n",
    "        return r160.digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def double_sha256(data):\n",
    "        return hashlib.sha256(hashlib.sha256(data).digest()).digest()\n",
    "\n",
    "    @staticmethod\n",
    "    def format_hash(hash_):\n",
    "        return str(hexlify(hash_[::-1]).decode(\"utf-8\"))\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_uint32(data):\n",
    "        assert(len(data) == 4)\n",
    "        return struct.unpack(\"<I\", data)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_uint64(data):\n",
    "        assert(len(data) == 8)\n",
    "        return struct.unpack(\"<Q\", data)[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def decode_varint(data):\n",
    "        assert(len(data) > 0)\n",
    "        size = int(data[0])\n",
    "        assert(size <= 255)\n",
    "\n",
    "        if size < 253:\n",
    "            return size, 1\n",
    "\n",
    "        if size == 253:\n",
    "            format_ = '<H'\n",
    "        elif size == 254:\n",
    "            format_ = '<I'\n",
    "        elif size == 255:\n",
    "            format_ = '<Q'\n",
    "        else:\n",
    "            # Should never be reached\n",
    "            assert 0, \"unknown format_ for size : %s\" % size\n",
    "\n",
    "        size = struct.calcsize(format_)\n",
    "        return struct.unpack(format_, data[1:size+1])[0], size + 1\n",
    "    \n",
    "    @staticmethod\n",
    "    def format_json(json_obj, indent=2):\n",
    "        json_formatted_str = json.dumps(json_obj, indent=indent)\n",
    "        return json_formatted_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting db_structs/db_blockchain.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile 'db_structs/db_blockchain.py'\n",
    "\n",
    "import pymongo as pmng\n",
    "import mongoengine as mge\n",
    "from datetime import datetime\n",
    "import json\n",
    "from configparser import ConfigParser\n",
    "from btc_utils import BTCUtils as Utils\n",
    "from bson.binary import Binary as BsonBinary\n",
    "\n",
    "\n",
    "db_config = Utils.load_config('app.conf','mdb');\n",
    "config_data = dict(\n",
    "    username =  db_config['username'],\n",
    "    password =  db_config['passwd'],\n",
    "    host = db_config['host'],\n",
    "    port =  int(db_config['port']),\n",
    "    authentication_source=  db_config['auth_db']\n",
    ")\n",
    "\n",
    "def global_connect(conn_alias='chinnus_nas'):\n",
    "    mge.register_connection(alias=conn_alias, name=db_config['db_blockchain'], **config_data)\n",
    "    \n",
    "def global_disconnect(conn_alias='chinnus_nas'):\n",
    "    mge.disconnect(alias=conn_alias)\n",
    "\n",
    "class DBBlockchain(mge.Document):\n",
    "    blkchain_idx = mge.IntField();\n",
    "    blks_cnt  = mge.IntField();\n",
    "    blk_first  = mge.IntField();\n",
    "    blk_last  = mge.IntField();\n",
    "    is_processed  = mge.BooleanField(default=False);\n",
    "    \n",
    "    meta = {\n",
    "        'db_alias' : 'chinnus_nas',\n",
    "        'collection' : 'btc_blkchains'\n",
    "    }\n",
    "    \n",
    "    def from_btcpy_obj(self, blkIdx_obj):\n",
    "        self.blkchain_idx = blkIdx_obj.file;\n",
    "        #DBBlockchain.blks_cnt = BlocksCnt\n",
    "        #DBBlockchain.blks_first = btcpy_obj;\n",
    "        #DBBlockchain.blk_last = BlkLast\n",
    "        self.save()\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def setup(BlockchainIdx, BlocksCnt, BlkFirst, BlkLast):\n",
    "        DBBlockchain.blkchain_idx = BlockchainIdx;\n",
    "        DBBlockchain.blks_cnt = BlocksCnt\n",
    "        DBBlockchain.blks_first = BlkFirst;\n",
    "        DBBlockchain.blk_last = BlkLast\n",
    "    \n",
    "    def to_json(self):\n",
    "        return json.dumps({\n",
    "            blkchain_idx : self.blkchain_idx,\n",
    "            blks_cnt : self.blks_cnt,\n",
    "            blk_first : self.blk_first,\n",
    "            blk_last : self.blk_last,\n",
    "            is_processed : self.is_processed\n",
    "        }, indent=2)\n",
    "    \n",
    "    \n",
    "\n",
    "class DBBlock(mge.Document):\n",
    "    blk_height = mge.IntField()\n",
    "    blk_hash = mge.StringField()\n",
    "    blk_hash_prev = mge.StringField()\n",
    "    blkchain_idx = mge.IntField()\n",
    "    tx_cnt = mge.IntField();\n",
    "    is_processed = mge.BooleanField()\n",
    "    \n",
    "    meta = {\n",
    "        'db_alias' : 'chinnus_nas',\n",
    "        'collection' : 'btc_blks'\n",
    "    }\n",
    "    \n",
    "    @staticmethod\n",
    "    def setup(BlockHeight, BlockHash, PrevBlockHash, BlockchainIdx, TxCnt=0):\n",
    "        DBBlock.blk_height = BlockHeight,\n",
    "        DBBlock.blk_hash = BlockHash,\n",
    "        DBBlock.blk_hash_prev = PrevBlockHash,\n",
    "        DBBlock.blkchain_idx = BlockchainIdx,\n",
    "        DBBlock.tx_cnt = TxCnt\n",
    "    \n",
    "    def from_btcpy_obj(self, blkIdx_obj):\n",
    "        self.blk_height = blkIdx_obj.height;\n",
    "        self.blk_hash = blkIdx_obj.hash;\n",
    "        self.blk_hash_prev = blkIdx_obj.prev_hash;\n",
    "        self.blkchain_idx = blkIdx_obj.file;\n",
    "        self.tx_cnt = blkIdx_obj.n_tx;\n",
    "        self.save()\n",
    "\n",
    "    def to_json(self):\n",
    "        return json.dumps({\n",
    "            blk_height : self.blk_height,\n",
    "            blk_hash : self.blk_hash,\n",
    "            blk_hash_prev : self.blk_hash_prev,\n",
    "            blkchain_idx : self.blkchain_idx,\n",
    "            tx_cnt : self.tx_cnt,\n",
    "            is_processed : self.is_processed\n",
    "        }, indent=2)\n",
    "\n",
    "class DBTxi(mge.EmbeddedDocument):\n",
    "    txi_idx = mge.IntField()\n",
    "    txi_is_coinbase = mge.BooleanField()\n",
    "    prev_txo_txid = mge.StringField()\n",
    "    prev_txo_idx = mge.IntField()\n",
    "    btc_addr_from = mge.StringField()\n",
    "    i_script = mge.StringField()\n",
    "    i_script_asm = mge.StringField()\n",
    "    i_script_type = mge.StringField(default='scriptsig')\n",
    "    is_witness_signed = mge.BooleanField()\n",
    "    \n",
    "        \n",
    "    def from_btcpy_obj(self, idx, txi_obj, is_coinbase=False):        \n",
    "        if is_coinbase:\n",
    "            self.txi_idx = 0;\n",
    "            self.txi_is_coinbase = True;\n",
    "        else:\n",
    "            self.txi_idx = idx;\n",
    "            self.txi_is_coinbase = False;        \n",
    "            self.prev_txo_txid = txi_obj.txid\n",
    "            self.prev_txo_idx = txi_obj.txout\n",
    "            #btc_addr_from = mge.StringField()\n",
    "            self.i_script = txi_obj.script_sig.hexlify()\n",
    "            self.i_script_asm = str(txi_obj.script_sig)\n",
    "            self.i_script_type = txi_obj.script_sig.type\n",
    "            if txi_obj.witness is not None:\n",
    "                self.is_witness_signed = True;\n",
    "            \n",
    "    \n",
    "        \n",
    "    def to_json(self):\n",
    "        return json.dumps({\n",
    "            txi_idx : self.txi_idx,\n",
    "            txi_is_coinbase : self.txi_is_coinbse,\n",
    "            prev_txo_txid : self.prev_txo_txid,\n",
    "            prev_txo_idx : self.prev_txo_idx,\n",
    "            btc_addr_from : self.btc_addr_from,\n",
    "            i_script : self.i_script,\n",
    "            i_script_asm : self.i_script_asm,\n",
    "            i_script_type : self.i_script_type\n",
    "        }, indent=2)\n",
    "    \n",
    "    \n",
    "class DBTxo(mge.EmbeddedDocument):\n",
    "    txo_idx = mge.IntField();\n",
    "    btc_addr_to = mge.StringField();\n",
    "    btc_value = mge.FloatField();\n",
    "    o_script = mge.StringField();\n",
    "    o_script_asm = mge.StringField();\n",
    "    o_script_type = mge.StringField();\n",
    "    utxo = mge.BooleanField(default=True);\n",
    "    utxo_txid = mge.StringField()\n",
    "    \n",
    "    \n",
    "    def from_btcpy_obj(self, txo_obj):\n",
    "        self.txo_idx = txo_obj.n;        \n",
    "        self.btc_value = Utils.val_non_satoshi(txo_obj.value);\n",
    "        self.o_script = txo_obj.script_pubkey.hexlify();\n",
    "        self.o_script_asm = str(txo_obj.script_pubkey);\n",
    "        self.o_script_type = txo_obj.script_pubkey.type;\n",
    "        if txo_obj.script_pubkey.address is not None:\n",
    "            self.btc_addr_to = str(txo_obj.script_pubkey.address());\n",
    "        self.utxo = True;\n",
    "        \n",
    "\n",
    "    \n",
    "class DBTx(mge.Document):\n",
    "    txid = mge.StringField();\n",
    "    blk_height = mge.IntField();\n",
    "    #btc_addr_from = mge.StringField();\n",
    "    txi_cnt = mge.IntField();\n",
    "    txo_cnt = mge.IntField();\n",
    "    utxo = mge.BooleanField(default=True);\n",
    "    txis = mge.EmbeddedDocumentListField(DBTxi);\n",
    "    txos = mge.EmbeddedDocumentListField(DBTxo);\n",
    "    \n",
    "    meta = {\n",
    "        'db_alias' : 'chinnus_nas',\n",
    "        'collection' : 'btc_txs'\n",
    "    }\n",
    "    \n",
    "    def set_utxo_spent(self, txo_idx, utxo_status=False, utxo_txid=None):\n",
    "        self.txos[txo_idx].utxo = utxo_status;\n",
    "        if utxo_txid is not None:\n",
    "            self.txos[txo_idx].utxo_txid = utxo_txid;\n",
    "        \n",
    "    \n",
    "    def from_btcpy_obj(self, blkidx_obj, txn_obj):\n",
    "        self.txid = txn_obj.txid;\n",
    "        self.blk_height = blkidx_obj.height;\n",
    "        self.txi_cnt = len(txn_obj.ins);\n",
    "        self.txo_cnt = len(txn_obj.outs);\n",
    "        self.utxo = True;\n",
    "        self.txis = [];\n",
    "        if txn_obj.is_coinbase():\n",
    "            for txin in txn_obj.ins:\n",
    "                txi_obj = DBTxi();\n",
    "                txi_obj.from_btcpy_obj(txn_obj.ins.index(txin), txin, True)\n",
    "                self.txis.append(txi_obj)\n",
    "        else:\n",
    "            for txin in txn_obj.ins:\n",
    "                txi_obj = DBTxi();\n",
    "                txi_obj.from_btcpy_obj(txn_obj.ins.index(txin), txin, False)\n",
    "                self.txis.append(txi_obj)\n",
    "                update_fields = { f'set__txos__{txin.txout}__utxo': False,\n",
    "                                 f'set__txos__{txin.txout}__utxo_txid': self.txid}\n",
    "                \n",
    "                DBTx.objects.get(txid=txin.txid).update(**update_fields)\n",
    "        self.txos = [];\n",
    "        for txout in txn_obj.outs:\n",
    "            txo_obj = DBTxo();            \n",
    "            txo_obj.from_btcpy_obj(txout)\n",
    "            self.txos.append(txo_obj)\n",
    "        self.save()\n",
    "        \n",
    "\n",
    "\n",
    "class DBUtxo(mge.Document):\n",
    "    txid = mge.StringField();\n",
    "    txo_idx = mge.IntField();\n",
    "    txid_oidx = mge.StringField();\n",
    "    blkchain_idx = mge.IntField();    \n",
    "    blk_height = mge.IntField();\n",
    "    btc_addr_to = mge.StringField();\n",
    "    btc_value = mge.FloatField();\n",
    "    o_script = mge.StringField();\n",
    "    o_script_asm = mge.StringField();\n",
    "    o_script_type = mge.StringField();\n",
    "    is_utxo = mge.BooleanField();\n",
    "    \n",
    "    \n",
    "    def delete_spent(self, i_txid, io_idx):\n",
    "        #DBUtxo.objects.get(txid=i_txid, txo_idx=io_idx).delete()\n",
    "        txid_oidx_key = i_txid + \"-\" + str(io_idx);    \n",
    "            \n",
    "        try:\n",
    "            obj_to_delete = DBUtxo.objects(txid_oidx = txid_oidx_key ).first();\n",
    "            if obj_to_delete is not None:\n",
    "                obj_to_delete.delete()\n",
    "        except: #(mge.DoesNotExist) as e:\n",
    "            #print(\"Does not exist error{0}: {1}\".format(e.args, txid_oidx_key,))\n",
    "            print(\"Does not exist error: {0}\".format(txid_oidx_key))\n",
    "        \n",
    "        \n",
    "    def del_from_btcpy_obj(self, txn_obj):\n",
    "        if not txn_obj.is_coinbase():\n",
    "            for txin in txn_obj.ins:\n",
    "                self.delete_spent(txin.txid, txin.txout)\n",
    "    \n",
    "       \n",
    "    def add_from_btcpy_obj(self, blkidx_obj, txn_obj, txo_obj):\n",
    "        try:\n",
    "            utxo_obj = DBUtxo();\n",
    "            utxo_obj.txid = txn_obj.txid;\n",
    "            utxo_obj.txo_idx = txo_obj.n;\n",
    "            utxo_obj.txid_oidx = txn_obj.txid + \"-\" + str(txo_obj.n);\n",
    "            utxo_obj.blkchain_idx = blkidx_obj.file;\n",
    "            utxo_obj.blk_height = blkidx_obj.height;\n",
    "            if txo_obj.script_pubkey.address() is not None:\n",
    "                utxo_obj.btc_addr_to = str(txo_obj.script_pubkey.address());\n",
    "            utxo_obj.btc_value = Utils.val_non_satoshi(txo_obj.value);\n",
    "            utxo_obj.o_script = txo_obj.script_pubkey.hexlify();\n",
    "            utxo_obj.o_script_asm = str(txo_obj.script_pubkey);\n",
    "            utxo_obj.o_script_type = txo_obj.script_pubkey.type;\n",
    "            utxo_obj.is_utxo = True;\n",
    "            utxo_obj.save();\n",
    "        except (pmng.errors.DuplicateKeyError, mge.errors.NotUniqueError) as e:\n",
    "            print(\"Duplicate key error({0}): {1}\".format(e.args, utxo_obj.txid_oidx))\n",
    "        \n",
    "    def from_btcpy_obj(self, blkidx_obj, txn_obj):      \n",
    "        for txo_obj in txn_obj.outs:\n",
    "            self.add_from_btcpy_obj(blkidx_obj, txn_obj, txo_obj);\n",
    "            \n",
    "        if not txn_obj.is_coinbase():\n",
    "            for txi_obj in txn_obj.ins:\n",
    "                self.delete_spent(txi_obj.txid, txi_obj.txout);\n",
    "                \n",
    "    def from_btcpy_obj_mp(self, blkidx_obj, txn_obj, q_del):\n",
    "        for txo_obj in txn_obj.outs:\n",
    "            self.add_from_btcpy_obj(blkidx_obj, txn_obj, txo_obj);\n",
    "            \n",
    "        if not txn_obj.is_coinbase():\n",
    "            for txi_obj in txn_obj.ins:                \n",
    "                q_del.put(txi_obj.txid + \"-\" + str(txi_obj.txout)); #for non-coinbse txns, add txid_oidx to q for future handling\n",
    "\n",
    "                \n",
    "    meta = {\n",
    "        'db_alias' : 'chinnus_nas',\n",
    "        'collection' : 'btc_utxos'\n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "class DBDirectory(mge.Document):\n",
    "    btc_addr = mge.StringField();\n",
    "    btc_addr_type = mge.StringField();\n",
    "    btc_addr_is_segwit = mge.BooleanField();\n",
    "    btc_addr_p2pkh = mge.StringField();\n",
    "    btc_addr_p2wpkh = mge.StringField();\n",
    "    btc_addr_p2sh = mge.StringField();\n",
    "    btc_addr_p2wsh = mge.StringField();\n",
    "    btc_addr_bech32 = mge.StringField();\n",
    "    pbk = mge.BinaryField();\n",
    "    hash160 = mge.BinaryField();\n",
    "    pvk = mge.BinaryField();\n",
    "    bal = mge.FloatField();\n",
    "    bal_asof = mge.DateTimeField();\n",
    "    utxo = mge.BooleanField(default=True);\n",
    "    txis = mge.ListField()\n",
    "    txos = mge.ListField()\n",
    "    \n",
    "    meta = {\n",
    "        'db_alias' : 'chinnus_nas',\n",
    "        'collection' : 'btc_directory'\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import binascii\n",
    "st = \"somdd\"\n",
    "print(\"Bytes: \", bytes(st, 'utf-8'))\n",
    "\n",
    "print(\"hex \", binascii.hexlify(bytes(st, 'utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from btc_utils import BTCUtils as Utils\n",
    "\n",
    "hash_s = \"000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f\"\n",
    "bson_bin = Utils.s2bson(hash_s)\n",
    "print(type(bson_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Utils.x2b(Utils.s2x(hash_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vins = [\n",
    "    {\n",
    "      \"coinbase\": {\n",
    "        \"hex\": \"048bdb051a025a03062f503253482f\"\n",
    "      },\n",
    "      \"sequence\": \"4294967295\"\n",
    "    },{'script':\"scrisps\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_structs.db_blockchain import DBTxi, DBTxo, DBTx\n",
    "\n",
    "[DBTxi().from_btcpy_obj(vins.index(vin), vin, True) for vin in vins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2;\n",
    "print('set__txos__{0}__utxo'.format(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    coinbase = None;\n",
    "    \n",
    "    def set_coinbase(self, bl=False):\n",
    "        self.coinbase = bl;\n",
    "        \n",
    "    def get_coinbase(self):\n",
    "        return self.coinbase;\n",
    "        \n",
    "        \n",
    "t = test()\n",
    "t.set_coinbase(True)\n",
    "    \n",
    "t.get_coinbase()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not t.get_coinbase():\n",
    "    print( \"False\")\n",
    "else:\n",
    "    print(\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyception import AttributeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
